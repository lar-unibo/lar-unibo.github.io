<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Deformable Linear Objects - LAR @ UNIBO</title>
<meta name="description" content="Website for the LAR at the DEI-UNIBO">


  <meta name="author" content="Riccardo Zanella">
  


<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="LAR @ UNIBO">
<meta property="og:title" content="Deformable Linear Objects">
<meta property="og:url" content="http://localhost:4000/deformable_linear_objects/">


  <meta property="og:description" content="Website for the LAR at the DEI-UNIBO">











  

  


<link rel="canonical" href="http://localhost:4000/deformable_linear_objects/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="LAR @ UNIBO Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>


  
    <script src="/assets/js/mod_bibtex_js.js"></script>
  


    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--splash wide" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          LAR @ UNIBO
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/research/"
                
                
              >Research</a>
            </li><li class="masthead__menu-item">
              <a
                href="/projects/"
                
                
              >Projects</a>
            </li><li class="masthead__menu-item">
              <a
                href="/people/"
                
                
              >People</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      

<div id="main" role="main">
  <article class="splash" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Deformable Linear Objects">
    
    
    

    <section class="page__content" itemprop="text">
      <h1>Robotic Perception and Manipulation of Deformable Linear Objects
</h1>

<p>Page Structure:</p>
<ul>
  <li><a href="#vision-based-dataset-generation">Vision-based Dataset Generation</a></li>
  <li><a href="#2d-perception">2D Perception</a></li>
  <li><a href="#3d-perception">3D Perception</a></li>
  <li><a href="#manipulation">Manipulation</a></li>
</ul>

<hr style="border:1px solid gray" />

<h1 id="vision-based-dataset-generation">Vision-based Dataset Generation</h1>

<div class="feature__wrapper">

  
    <div class="feature__item--left">
      <div class="archive__item">
        
          <div class="archive__item-teaser">
            <img src="/files/images/topics/ck_dataset.jpg" alt="" />
            
          </div>
        

        <div class="archive__item-body">
          
            <h2 class="archive__item-title">Auto-generated Wires Dataset for Semantic Segmentation with Domain-Independence</h2>
          

          
            <div class="archive__item-excerpt">
              
<p>A procedure to automatically generate an high-quality training dataset of cable-like objects for semantic segmentation. The proposed method is explained in detail using the recognition of electric wires as a use case. These particular objects are commonly used in an extremely wide set of industrial applications, since they are of information and communication infrastructures, they are used in construction, industrial manufacturing and power distribution. The proposed approach uses an image of the target object placed in front of a monochromatic background. By employing the chroma-key technique, we can easily obtain the training masks of the target object and replace the background to produce a domain-independent dataset. How to reduce the reality gap is also investigated in this work by correctly choosing the backgrounds, augmenting the foreground images exploiting masks. The produced dataset is experimentally validated by training two algorithms and testing them on a real image set. Moreover, they are compared to a baseline algorithm specifically designed to recognise deformable linear objects.
<a href="https://ieeexplore.ieee.org/document/9349395">Paper</a> /  <a href="https://www.kaggle.com/datasets/zanellar/electric-wires-image-segmentation">Dataset</a></p>

            </div>
          

          
        </div>
      </div>
    </div>
  

</div>

<div class="feature__wrapper">

  
    <div class="feature__item--left">
      <div class="archive__item">
        
          <div class="archive__item-teaser">
            <img src="/files/images/topics/DLO_WSL.jpg" alt="" />
            
          </div>
        

        <div class="archive__item-body">
          
            <h2 class="archive__item-title">A Weakly Supervised Semi-Automatic Image Labeling Approach for Deformable Linear Objects</h2>
          

          
            <div class="archive__item-excerpt">
              
<p>DLO-WSL: A methodology for generating datasets to train Deformable Linear Object (DLO) segmentation approaches involving combining synthetic and real samples.  The process includes labeling key points on a real-world DLO using a VR tracker operated by a user. The datasets, comprising synthetic and real-world samples, are then used to train deep learning algorithms for semantic and instance segmentation. A user study and parameter analysis validate the method, demonstrating that VR tracker labeling is effective and reduces the number of clicks compared to alternative techniques. The results also indicate that blending real-world and synthetic DLO data enhances the Intersection over Union (IoU) score of a semantic segmentation algorithm by approximately 5%, highlighting the potential for improved segmentation algorithm performance when using a combination of real-world and synthetic data.
<a href="https://ieeexplore.ieee.org/document/10008018">Paper</a> /  <a href="https://github.com/lar-unibo/DLO-WSL">Code</a> /  <a href="https://www.youtube.com/watch?v=5F7tf9swhvw&amp;t=1s">Video</a></p>

            </div>
          

          
        </div>
      </div>
    </div>
  

</div>

<h1 id="2d-perception">2D Perception</h1>

<div class="feature__wrapper">

  
    <div class="feature__item--left">
      <div class="archive__item">
        
          <div class="archive__item-teaser">
            <img src="/files/images/topics/ariadne_plus.jpg" alt="" />
            
          </div>
        

        <div class="archive__item-body">
          
            <h2 class="archive__item-title">Ariadne+ -- Deep Learning-Based Augmented Framework for the Instance Segmentation of Wires</h2>
          

          
            <div class="archive__item-excerpt">
              
<p>In this article, an innovative algorithm for instance segmentation of wires called Ariadne+ is presented. Although vastly present in many manufacturing environments, the perception and manipulation of wires is still an open problem for robotic applications. Wires are deformable linear objects lacking of any specific shape, color, and feature. The proposed approach uses deep learning and standard computer vision techniques aiming at their reliable and time effective instance segmentation. A deep convolutional neural network is employed to generate a binary mask showing where wires are present in the input image, then the graph theory is applied to create the wire paths from the binary mask through an iterative approach that aims to maximize the graph coverage. In addition, the B-Spline model of each instance, useful in manipulation tasks, is provided. The approach has been validated quantitatively and qualitatively using a manually labeled test dataset and by comparing it against the original Ariadne algorithm. The timings performances of the approach have been also analyzed in depth.
<a href="https://ieeexplore.ieee.org/document/9721686">Paper</a> /  <a href="https://github.com/lar-unibo/ariadne_plus">Code</a></p>

            </div>
          

          
        </div>
      </div>
    </div>
  

</div>

<div class="feature__wrapper">

  
    <div class="feature__item--left">
      <div class="archive__item">
        
          <div class="archive__item-teaser">
            <img src="/files/images/topics/fastdlo.jpg" alt="" />
            
          </div>
        

        <div class="archive__item-body">
          
            <h2 class="archive__item-title">FASTDLO -- Fast Deformable Linear Objects Instance Segmentation</h2>
          

          
            <div class="archive__item-excerpt">
              
<p>In this paper, an approach for fast and accurate segmentation of Deformable Linear Objects (DLOs) named FASTDLO is presented. A deep convolutional neural network is employed for background segmentation, generating a binary mask that isolates DLOs in the image. Thereafter, the obtained mask is processed with a skeletonization algorithm and the intersections between different DLOs are solved with a similarity-based network. Apart from the usual pixel-wise color-mapped image, FASTDLO also describes each DLO instance with a sequence of 2D coordinates, enabling the possibility of modeling the DLO instances with splines curves, for example. Synthetically generated data are exploited for the training of the data-driven methods, avoiding expensive collection and annotations of real data. FASTDLO is experimentally compared against both a DLO-specific approach and general-purpose deep learning instance segmentation models, achieving better overall performances and a processing rate higher than 20 FPS.
<a href="https://ieeexplore.ieee.org/document/9830852">Paper</a> /  <a href="https://github.com/lar-unibo/fastdlo">Code</a></p>

            </div>
          

          
        </div>
      </div>
    </div>
  

</div>

<div class="feature__wrapper">

  
    <div class="feature__item--left">
      <div class="archive__item">
        
          <div class="archive__item-teaser">
            <img src="/files/images/topics/RTDLO.jpg" alt="" />
            
          </div>
        

        <div class="archive__item-body">
          
            <h2 class="archive__item-title">RT-DLO -- Real-Time Deformable Linear Objects Instance Segmentation</h2>
          

          
            <div class="archive__item-excerpt">
              
<p>Deformable linear objects (DLOs), such as cables, wires, ropes, and elastic tubes, are numerously present both in domestic and industrial environments. Unfortunately, robotic systems handling DLOs are rare and have limited capabilities due to the challenging nature of perceiving them. Hence, we propose a novel approach named RT-DLO for real-time instance segmentation of DLOs. First, the DLOs are semantically segmented from the background. Afterward, a novel method to separate the DLO instances is applied. It employs the generation of a graph representation of the scene given the semantic mask where the graph nodes are sampled from the DLOs center-lines whereas the graph edges are selected based on topological reasoning. RT-DLO is experimentally evaluated against both DLO-specific and general-purpose instance segmentation deep learning approaches, achieving overall better performances in terms of accuracy and inference time.
<a href="https://ieeexplore.ieee.org/document/10045806">Paper</a> /  <a href="https://github.com/lar-unibo/RT-DLO">Code</a></p>

            </div>
          

          
        </div>
      </div>
    </div>
  

</div>

<h1 id="3d-perception">3D Perception</h1>

<div class="feature__wrapper">

  
    <div class="feature__item--left">
      <div class="archive__item">
        
          <div class="archive__item-teaser">
            <img src="/files/images/topics/DLO3DS.jpg" alt="" />
            
          </div>
        

        <div class="archive__item-body">
          
            <h2 class="archive__item-title">Deformable Linear Objects 3D Shape Estimation and Tracking From Multiple 2D Views</h2>
          

          
            <div class="archive__item-excerpt">
              
<p>This letter presents DLO3DS , an approach for the 3D shapes estimation and tracking of Deformable Linear Objects (DLOs) such as cables, wires or plastic hoses, using a cheap and compact 2D vision sensor mounted on the robot end-effector. DLO3DS can be applied in all those scenarios in which the perception and manipulation of DLO-like structures are needed, such as in the case of switchgear cabling, wiring harness manufacturing and assembly in the automotive and aerospace industries, or production of hoses for medical applications. The developed procedure is based on a pipeline that first processes the images coming from the 2D camera extracting key topological points along the DLOs. These points are then used to model each DLO with a B-spline curve. Finally, the set of splines obtained from all the images is matched by exploiting a multi-view stereo-based algorithm. DLO3DS is validated both on a real scenario and on simulated data obtained by exploiting a rendering engine for photo-realistic images. In this way, reliable ground-truth data are retrieved and utilized for assessing the estimation error achievable by DLO3DS , which on the employed test set is characterized by a mean reconstruction error of 0.82 mm.
<a href="https://ieeexplore.ieee.org/document/10120758">Paper</a> /  <a href="https://github.com/lar-unibo/DLO3DS">Code</a></p>

            </div>
          

          
        </div>
      </div>
    </div>
  

</div>

<h1 id="manipulation">Manipulation</h1>

<div class="feature__wrapper">

  
    <div class="feature__item--left">
      <div class="archive__item">
        
          <div class="archive__item-teaser">
            <img src="/files/images/topics/dlo_manipulation.jpg" alt="" />
            
          </div>
        

        <div class="archive__item-body">
          
            <h2 class="archive__item-title">Deformable Linear Objects Manipulation with Online Model Parameters Estimation</h2>
          

          
            <div class="archive__item-excerpt">
              
<p>Manipulating Deformable Linear Objects (DLOs) is a challenging task for a robotic system due to their unpredictable configuration, high-dimensional state space and complex nonlinear dynamics. This paper presents a framework addressing the manipulation of DLOs, specifically targeting the model-based shape control task with the simultaneous online gradient-based estimation of model parameters. In the proposed framework, a neural network is trained to mimic the DLO dynamics using the data generated with an analytical DLO model for a broad spectrum of its parameters. The neural network-based DLO model is conditioned on these parameters and employed in an online phase to perform the shape control task by estimating the optimal manipulative action through a gradient-based procedure. In parallel, gradient-based optimization is used to adapt the DLO model parameters to make the neural network-based model better capture the dynamics of the real-world DLO being manipulated and match the observed deformations. To assess its effectiveness, the framework is tested across a variety of DLOs, surfaces, and target shapes in a series of experiments. The results of these experiments demonstrate the validity and efficiency of the proposed methodology compared to existing methods.
<a href="https://ieeexplore.ieee.org/document/10412116">Paper</a> /  <a href="https://github.com/lar-unibo/dlo_manipulation_online_params">Code</a> /  <a href="https://sites.google.com/view/dlo-manipulation">Project_Website</a></p>

            </div>
          

          
        </div>
      </div>
    </div>
  

</div>


    </section>
  </article>
</div>

      
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://github.com/lar-unibo/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 <a href="http://localhost:4000">LAR @ UNIBO</a>. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/jekyll-themes/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>









  </body>
</html>
